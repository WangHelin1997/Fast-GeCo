Task,Dataset,Script_file,Hparam_file,Data_prep_file,Readme_file,Result_url,HF_repo,test_debug_flags,test_debug_checks,performance
Tokenizer,Tedlium2,recipes/Tedlium2/Tokenizer/train.py,recipes/Tedlium2/Tokenizer/hparams/tedlium2_500_bpe.yaml,recipes/Tedlium2/Tokenizer/tedlium2_prepare.py,recipes/Tedlium2/Tokenizer/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --skip_prep=True --token_output=23 --clipped_utt_folder=None,,
ASR,Tedlium2,recipes/Tedlium2/ASR/transformer/train.py,recipes/Tedlium2/ASR/transformer/hparams/branchformer_large.yaml,recipes/Tedlium2/Tokenizer/tedlium2_prepare.py,recipes/Tedlium2/ASR/transformer/README.md,https://www.dropbox.com/sh/el523uofs96czfi/AADgTd838pKo2aR8fhqVOh-Oa?dl=0,https://huggingface.co/speechbrain/asr-branchformer-large-tedlium2,--data_folder=. --clipped_utt_folder=. --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --output_neurons=23 --number_of_epochs=10 --skip_prep=True --test_beam_size=1 --valid_beam_size=1 --pretrained_tokenizer_file=tests/tmp/Tedlium2_row_02/23_bpe.model,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer_ASR_train.txt,save/tokenizer.ckpt] performance_check=[train_log.txt, train loss, <500, epoch: 10]",Test-WER_No_LM=8.11%
